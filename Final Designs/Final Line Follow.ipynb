{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efdf2394",
   "metadata": {},
   "source": [
    "<h1>Line Following Algorithm</h1>\n",
    "<h2>Step 1: Colour Identification</h2>\n",
    "<p>The first step is to define the functions that take an image and convert it into the output image of the image processing pipeline.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "845be119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Convert yellow in image\n",
    "def getYellow(color):\n",
    "    blurred = cv2.GaussianBlur(color, (3, 3), 0)\n",
    "\n",
    "    # Convert to HSV\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    mask = cv2.inRange(hsv, (15, 25, 25), (50, 255,255))\n",
    "\n",
    "    # Slice the Yellow\n",
    "    imask = mask>0\n",
    "    yellow = np.zeros_like(blurred, np.uint8)\n",
    "    \n",
    "    # Apply mask\n",
    "    yellow[imask] = blurred[imask]\n",
    "\n",
    "    gray = cv2.cvtColor(yellow, cv2.COLOR_BGR2GRAY) \n",
    "    \n",
    "    # Apply binary thershold\n",
    "    (T, thresh) = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY) \n",
    "\n",
    "    # Remove ignored ignore regions\n",
    "    thresh[:40,:]=0 #top\n",
    "\n",
    "    return thresh\n",
    "\n",
    "# Convert blue in image\n",
    "def getBlue(color):\n",
    "    blurred = cv2.GaussianBlur(color, (3, 3), 0)\n",
    "\n",
    "    # Convert to HSV\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    mask = cv2.inRange(hsv, (90, 80, 25), (105, 255,255))\n",
    "    \n",
    "    # Slice the Blue\n",
    "    imask = mask>0\n",
    "    blue = np.zeros_like(blurred, np.uint8)\n",
    "    \n",
    "    # Apply the mask\n",
    "    blue[imask] = blurred[imask]\n",
    "\n",
    "    gray = cv2.cvtColor(blue, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #cApply binary threshold\n",
    "    (T, thresh) = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Remove ignored ignore regions\n",
    "    thresh[:40,:]=0 #top\n",
    "    \n",
    "    return thresh\n",
    "\n",
    "# Get the number of white pixels in the image\n",
    "def getWhite(image):\n",
    "    return np.sum(image == 255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a769b",
   "metadata": {},
   "source": [
    "<h2>Step 2: Define and Initailise Camera Classs </h2>\n",
    "The next step is to define the camera class and the capture frames method which is also used to get the processed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b4b1f5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "failed to set power state",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0729e865eb43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m#create a camera object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mcamera\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# start capturing the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/traitlets/config/configurable.py\u001b[0m in \u001b[0;36minstance\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;31m# Create and save the instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0minst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m             \u001b[0;31m# Now make sure that the instance will also be returned by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0;31m# parent classes' _instance attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-0729e865eb43>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m#start the RGBD sensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: failed to set power state"
     ]
    }
   ],
   "source": [
    "#use traitlets and widgets to display the image in Jupyter Notebook\n",
    "import traitlets\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "\n",
    "#use opencv \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#using realsense to capture the color image\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "#multi-threading is used to capture the image in real time performance\n",
    "import threading\n",
    "\n",
    "class Camera(SingletonConfigurable):\n",
    "    \n",
    "    #this changing of this value will be captured by traitlets\n",
    "    color_value = traitlets.Any()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Camera, self).__init__()\n",
    "        \n",
    "        #configure the color sensor\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.configuration = rs.config()\n",
    "        self.flag = 0\n",
    "        self.count = 0\n",
    "        self.line_color = 0\n",
    "        self.predict = [0,0,0,0,0,0,0,0,0]\n",
    "        \n",
    "        #set resolution for the color camera\n",
    "        self.color_width = 640\n",
    "        self.color_height = 480\n",
    "        self.color_fps = 30\n",
    "        self.configuration.enable_stream(rs.stream.color, self.color_width, self.color_height, rs.format.bgr8, self.color_fps)\n",
    "\n",
    "        #flag to control the thread\n",
    "        self.thread_runnning_flag = False\n",
    "        \n",
    "        #start the RGBD sensor\n",
    "        self.pipeline.start(self.configuration)\n",
    "        self.pipeline_started = True\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "\n",
    "        #start capture the first color image\n",
    "        color_frame = frames.get_color_frame()   \n",
    "        image = np.asanyarray(color_frame.get_data())\n",
    "        self.color_value = image\n",
    "\n",
    "        \n",
    "    def _capture_frames(self):\n",
    "        while(self.thread_runnning_flag==True): #continue until the thread_runnning_flag is set to be False\n",
    "            frames = self.pipeline.wait_for_frames() #receive data from RGBD sensor\n",
    "            \n",
    "            color_frame = frames.get_color_frame() #get the color image\n",
    "            image = np.asanyarray(color_frame.get_data()) #convert color image to numpy array\n",
    "            self.color_value = image #assign the numpy array image to the color_value variable \n",
    "            \n",
    "            # Identitfy color of rope in the current frame and update poll\n",
    "            if getWhite(getYellow(image)) > getWhite(getBlue(image)):\n",
    "                self.predict = [1]+self.predict[:-1]\n",
    "            else: self.predict = [-1]+self.predict[:-1]\n",
    "            \n",
    "            # Check poll to find the current rope colour\n",
    "            if sum(self.predict) >= 0:\n",
    "                self.line_color = 0\n",
    "            if sum(self.predict) < 0:\n",
    "                self.line_color = 1\n",
    "           \n",
    "    def start(self): #start the data capture thread\n",
    "        if self.thread_runnning_flag == False: #only process if no thread is running yet\n",
    "            self.thread_runnning_flag=True #flag to control the operation of the _capture_frames function\n",
    "            self.thread = threading.Thread(target=self._capture_frames) #link thread with the function\n",
    "            self.thread.start() #start the thread\n",
    "\n",
    "    def stop(self): #stop the data capture thread\n",
    "        if self.thread_runnning_flag == True:\n",
    "            self.thread_runnning_flag = False #exit the while loop in the _capture_frames\n",
    "            self.thread.join() #wait the exiting of the thread       \n",
    "\n",
    "def bgr8_to_jpeg(value):#convert numpy array to jpeg coded data for displaying \n",
    "    return bytes(cv2.imencode('.jpg',value)[1])\n",
    "\n",
    "#create a camera object\n",
    "camera = Camera.instance()\n",
    "camera.start() # start capturing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6952bdd9",
   "metadata": {},
   "source": [
    "<h2>Step 3: Define the Process Update Function</h2>\n",
    "<p>Start the camera and dispay the processed image. Then analyse the image to identify what action the robot should perform. <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "470e9046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da01e70a4564a7d92599ed19042a4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', width='45%')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import sys\n",
    "import time\n",
    "from RobotClass import Robot\n",
    "\n",
    "#initialize the Robot class\n",
    "robot = Robot()\n",
    "\n",
    "\n",
    "\n",
    "#create widgets for the displaying of the image\n",
    "display_image = widgets.Image(format='jpeg', width='45%') #determine the width of the YELLOW image\n",
    "#display_blue = widgets.Image(format='jpeg', width='45%')  #determine the width of the BLUE image\n",
    "layout=widgets.Layout(width='100%')\n",
    "\n",
    "#sidebyside = widgets.HBox([display_yellow, display_blue],layout=layout) #horizontal \n",
    "display(display_image) #display the widget\n",
    "\n",
    "\n",
    "\n",
    "#callback function, invoked when traitlets detects the changing of the color image\n",
    "def process(change):\n",
    "    image = change['new'] #retrieve data from the input dict\n",
    "    \n",
    "    # Display the image\n",
    "    if camera.line_color == 0:\n",
    "        display_image.value = bgr8_to_jpeg(getYellow(cv2.resize(image,(160,120))))\n",
    "        output_image = getYellow(cv2.resize(image,(160,120)))\n",
    "    if camera.line_color == 1:\n",
    "        display_image.value = bgr8_to_jpeg(getBlue(cv2.resize(image,(160,120))))\n",
    "        output_image = getBlue(cv2.resize(image,(160,120)))\n",
    "    \n",
    "    # Look for the amount of white in the image - ie the amount of path that the robot can see\n",
    "    if getWhite(output_image[:,60:100])>60:\n",
    "        camera.flag = 1\n",
    "    elif getWhite(output_image[:,:40])>60:\n",
    "        # Turn left\n",
    "        camera.flag = 2\n",
    "    elif getWhite(output_image[:,120:])>60:\n",
    "        # Turn right\n",
    "        camera.flag = 3\n",
    "\n",
    "\n",
    "\n",
    "camera.observe(process, names='color_value')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e5f626",
   "metadata": {},
   "source": [
    "<h2>Step 4: Create the robot movement loop</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fae2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from RobotClass import Robot\n",
    "\n",
    "#initialize the Robot class\n",
    "robot = Robot()\n",
    "\n",
    "#this for loop will probably runs for 10 seconds\n",
    "for i in range(800):\n",
    "    if camera.flag == 1:              # Forward flag\n",
    "        robot.forward(1) \n",
    "    elif camera.flag == 2:             # Left flag\n",
    "        robot.left(0.4)\n",
    "    elif camera.flag == 3:             # right flag\n",
    "        robot.right(0.4)\n",
    "    time.sleep(0.05)\n",
    "\n",
    "        \n",
    "#stop the robot\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c4f322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
